# PYNQ-ZU Complete Setup & Deployment Guide

**A Comprehensive Hardware-Accelerated Edge AI System for Real-Time Alzheimer's Classification**

This guide walks you through every step of setting up the PYNQ-ZU board with the Vitis AI Deep Learning Processor (DPU) for live Alzheimer's classification via webcam.

---

## System Architecture Overview

Your PYNQ-ZU board is a **heterogeneous computing system** - it combines:

- **ARM Cortex-A53 (CPU)**: 1.5 GHz quad-core processor on the PS (Processing System)
- **Xilinx Zynq UltraScale+ FPGA**: 117K LUTs, 1,248 DSPs in the PL (Programmable Logic)
- **Deep Learning Processor (DPU)**: Specialized co-processor for CNN operations

### Zynq UltraScale+ XCZU5EG-SFVC784 Specifications

The PYNQ-ZU uses the **Xilinx XCZU5EG** SoC with these resources:

| Resource | Count |
|----------|-------|
| System Logic Cells | 256 K |
| CLB Flip-Flops | 234 K |
| **CLB LUTs** | **117 K** |
| Total Block RAM (BRAM) | 5.1 Mb |
| Total Ultra RAM (URAM) | 18 Mb |
| **DSP Slices** | **1,248** |

This means:
- **ARM handles**: Video capture, preprocessing, control logic
- **FPGA handles**: CNN inference (7.7x faster than CPU!)
- **Result**: Real-time classification at 23 FPS vs 3 FPS on CPU alone

### Hardware/Software Partitioning: PS and PL

The Zynq UltraScale+ uses a **heterogeneous architecture** where functionality is split between Processing System (PS) and Programmable Logic (PL):

#### Processing System (PS) - ARM Cortex-A53

**Connected Peripherals:**
- 4GB DDR4 RAM
- Micro SD card port
- Mini Display Port (DP output)
- WiFi + Bluetooth Module
- 2Ã— 2-Stacked USB 3.0 Hubs
- USB 3.0 Composite Device (Micro USB 3.0)
- TPM Pmod
- I2C / PMBus
- UART (serial console)
- Grove Connector (1Ã—)

**Responsibilities:**
- Boot Linux kernel
- Run Jupyter Lab
- Manage video capture via V4L2
- Preprocess MRI images
- Control DPU via Vitis AI library
- Handle post-processing

#### Programmable Logic (PL) - FPGA Fabric

**Connected Peripherals:**
- HDMI In and HDMI Out
- Audio Codec
- FMC LPC (FPGA Mezzanine Card slot)
- Dual SYZYGY Interfaces
- 40-pin Raspberry Pi Connector
- Grove Connectors (2Ã—)
- Pmod Connectors (2Ã—)
- CSI Camera Interface
- XADC (Analog/Digital Converter)
- 4Ã— Switches, 4Ã— Push Buttons
- 4Ã— LEDs, 2Ã— RGB LEDs

**Responsibilities:**
- Deep Learning Processor (DPU) synthesis
- Convolution, pooling operations
- Data path optimization
- Direct Memory Access (DMA) to DDR4

### Memory Architecture & DMA

The PS and PL are tightly coupled:

![PS/PL Architecture & Memory Connections](images/PYNQ_ZU%20Block%20Diagram.png)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 XCZU5EG SoC                             â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Processing System (PS)                        â”‚   â”‚
â”‚  â”‚  ARM Cortex-A53 @ 1.5 GHz                     â”‚   â”‚
â”‚  â”‚  â”œâ”€ Linux Kernel                              â”‚   â”‚
â”‚  â”‚  â”œâ”€ Python 3.8+ Runtime                       â”‚   â”‚
â”‚  â”‚  â”œâ”€ Vitis AI Library                          â”‚   â”‚
â”‚  â”‚  â””â”€ Video Capture (V4L2)                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â†• AXI High Performance (128-bit)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Programmable Logic (PL)                        â”‚   â”‚
â”‚  â”‚ â”œâ”€ Deep Learning Processor (DPU - B4096)     â”‚   â”‚
â”‚  â”‚ â”‚  â€¢ 8Ã—16Ã—16 parallelism (2048 ops/cycle)    â”‚   â”‚
â”‚  â”‚ â”‚  â€¢ 300M MACs per inference                  â”‚   â”‚
â”‚  â”‚ â”œâ”€ BRAM/URAM (weights & feature maps)        â”‚   â”‚
â”‚  â”‚ â””â”€ DMA Controllers                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â†•                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Shared DDR4 Memory (4 GB)                      â”‚   â”‚
â”‚  â”‚ â”œâ”€ Image buffers                              â”‚   â”‚
â”‚  â”‚ â”œâ”€ Model weights (quantized)                  â”‚   â”‚
â”‚  â”‚ â”œâ”€ Feature maps                               â”‚   â”‚
â”‚  â”‚ â””â”€ Results                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key points:**
- PS and PL share DDR4 via AXI interconnect
- DMA allows FPGA to access memory without CPU overhead
- Accelerator Coherency Port (ACP) maintains cache coherency
- This shared memory is critical for fast CNN inference

---

## This means:
- **ARM handles**: Video capture, preprocessing, control logic
- **FPGA handles**: CNN inference (7.7x faster than CPU!)
- **Result**: Real-time classification at 23 FPS vs 3 FPS on CPU alone

---

## Hardware Requirements

**Essential Hardware:**
- PYNQ-ZU development board (Xilinx XCZU5EG MPSoC)
- USB webcam (UVC compliant - most standard webcams work)
- 12V DC power supply (3A minimum - important for DPU load spikes)
- 16GB Class 10 microSD card
- Ethernet cable (for Jupyter access - optional but recommended)
- Micro-USB cable (for serial console fallback)

**Why 3A power supply?** The DSP arrays in the DPU simultaneously switch state during matrix operations, creating large transient current spikes. A weak power supply will cause board resets.

**Software Stack:**
- PYNQ 3.0 image (or later) for ZU board
- Vitis AI 2.5 ecosystem
- Python 3.8+
- OpenCV (GPU-optimized image processing)
- XRT (Xilinx Runtime) drivers - manages PS/PL communication

---

## Phase 1: Firmware Initialization & OS Boot

![PYNQ-ZU Board Overview](images/PYNQ-ZU.png)

The PYNQ board goes through a sophisticated multi-stage boot process.

### What Happens During Boot

When you power on the board:

1. **First Stage Bootloader (FSBL)** runs from the Boot ROM
   - Initializes ARM Cortex-A53 clocks
   - Loads the base FPGA bitstream from microSD
   - Hands off to U-Boot

2. **U-Boot** runs (second stage bootloader)
   - Configures DDR4 memory
   - Loads the Linux kernel into RAM

3. **Linux Kernel** starts
   - Mounts the microSD root filesystem
   - Starts system services and Jupyter Lab server

**Total boot time:** ~30-45 seconds

### Step 1: Flash the SD Card

**Download PYNQ 3.0 for ZU:**
1. Visit [pynq.io](https://pynq.io)
2. Download the ZU variant image file (`.img`)
3. You'll get a ~4GB file

**Flash using Balena Etcher:**
1. Install [Balena Etcher](https://www.balena.io/etcher/)
2. Launch Etcher
3. Select the PYNQ image
4. Select your microSD card (âš ï¸ double-check the drive letter!)
5. Click "Flash"
6. Wait 5-10 minutes

### Step 2: First Power-On

![PYNQ-ZU Board Components and LEDs](images/PYNQ_ZUcomponents.png)

1. Ensure microSD card is fully inserted (click until it stops)
2. Connect 12V power supply
3. Wait 30 seconds
4. Check LEDs:
   - Green LED (LD1) should be solid
   - Blue LED (LD2) may blink (normal during boot)
   - Red LED (LD3) should NOT be on (if on, power problem)

### Step 3: Verify Network Connectivity

**Via Ethernet (recommended):**

The board creates a hostname `pynq` on your network. From your laptop:

```bash
# Windows/Mac/Linux
ping pynq

# You should see:
# Reply from 192.168.x.x: bytes=32 time=5ms TTL=64
```

If ping fails, check your router's DHCP client list for "pynq" device.

---

## Phase 2: Access the Jupyter IDE

Once the board is booted and connected, you'll interact with it via Jupyter Lab (a web-based Python IDE).

![PYNQ-ZU Top View and Board Layout](images/top%20view%20of%20PYNQ_ZU.png)

### Connecting to Jupyter

Open your browser and go to: **`http://pynq:9090`**

You'll see a login screen:
- **Username:** `xilinx`
- **Password:** `xilinx`

You're now in Jupyter Lab! This is where you'll run Python scripts and upload files to the board.

### Opening a Terminal

To run bash commands on the board:
1. Click "New" in the top-left
2. Select "Terminal"
3. You get a shell prompt on the board

**Quick terminal test:**
```bash
uname -a
# Should show: Linux pynq 5.15.x aarch64

python3 --version
# Should show Python 3.8 or 3.9
```

---

## Phase 3: Environment Provisioning

The board comes with a base OS, but you need to install additional libraries for video capture and deep learning.

### Step 1: Update Package Repositories

Open a terminal in Jupyter and run:

```bash
sudo apt-get update
sudo apt-get upgrade -y
```

This takes ~5-10 minutes.

### Step 2: Install Image Processing Libraries

```bash
# OpenCV dependencies
sudo apt-get install -y libsm6 libxext6

# Install Python OpenCV
sudo apt-get install -y python3-opencv
```

### Step 3: Install Vitis AI Deep Learning Library

```bash
# Install pynq-dpu bindings for DPU access
pip3 install pynq-dpu --no-build-isolation

# Verify installation
python3 -c "from pynq_dpu import DpuOverlay; print('âœ“ DPU library OK')"
```

### Step 4: Install Additional Dependencies

```bash
pip install --upgrade pip
pip install tensorflow numpy scipy scikit-learn
pip install pillow matplotlib
```

### Verify Everything

```python
import cv2
import numpy as np
import tensorflow as tf
from pynq_dpu import DpuOverlay

print("âœ“ All imports successful!")
```

---

## Phase 4: Transfer Model & Bitstream Files

### What Files Do You Need?

| File | Purpose | Size |
|------|---------|------|
| `dpu.bit` | FPGA bitstream | ~5-10 MB |
| `dpu.hwh` | Hardware metadata (**critical!**) | ~1 KB |
| `dpu.xclbin` | DPU executable | ~2-5 MB |
| `dpu.xmodel` | Quantized MobileNetV2 model | ~3.5 MB |

**The `.hwh` file is crucial.** It tells PYNQ where the DPU lives in memory, its clock frequency, and interrupt lines.

### How to Transfer Files

**Method 1: Jupyter Upload (Easy)**
1. In Jupyter file browser, navigate to `/home/xilinx/`
2. Click "Upload" button
3. Select all `.bit`, `.hwh`, `.xclbin`, `.xmodel` files
4. Wait for upload

**Method 2: SCP from Laptop (Fast)**
```bash
scp dpu.* xilinx@pynq:/home/xilinx/
scp alzheimer_mobilenetv2_final.keras xilinx@pynq:/home/xilinx/
```

### Verify Files Transferred

```bash
ls -lh /home/xilinx/dpu.*

# You should see:
# -rw-r--r-- dpu.bit
# -rw-r--r-- dpu.hwh
# -rw-r--r-- dpu.xclbin
# -rw-r--r-- dpu.xmodel
```

---

## Phase 5: Hardware Peripheral Verification

### Test DPU Initialization

Create `test_dpu.py`:

```python
from pynq_dpu import DpuOverlay

print("Loading DPU overlay...")
try:
    overlay = DpuOverlay("dpu.bit")
    dpu = overlay.runner
    print("âœ“ DPU loaded successfully!")
    print(f"  Input shape: {dpu.get_input_shape()}")
    print(f"  Output shape: {dpu.get_output_shape()}")
except Exception as e:
    print(f"âœ— Failed: {e}")
```

Run it: `python3 test_dpu.py`

### Test Webcam Detection

```bash
# List video devices
ls /dev/video*

# Should show: /dev/video0
```

### Grant Webcam Permissions

```bash
sudo chmod 666 /dev/video0
```

### Test Webcam Stream

```python
import cv2

cap = cv2.VideoCapture(0)
if cap.isOpened():
    ret, frame = cap.read()
    if ret:
        print(f"âœ“ Webcam works: {frame.shape}")
        cv2.imwrite('test.png', frame)
else:
    print("âœ— Webcam failed")
```

---

## Phase 6: Live Webcam Inference

### The Complete Inference Script

Create `webcam_inference.py`:

![Real-time Inference Pipeline](images/PYNQ_ZU%20Board%20setup.png)

```python
#!/usr/bin/env python3
"""
Real-time Alzheimer Classification using PYNQ-ZU + DPU
"""

import cv2
import numpy as np
from pynq_dpu import DpuOverlay
import threading
import queue
import time

# Load DPU
print("Loading DPU overlay...")
overlay = DpuOverlay("dpu.bit")
dpu = overlay.runner
print("âœ“ DPU loaded!")

# Class definitions
CLASS_NAMES = [
    'Non-Demented',
    'Very Mild Dementia',
    'Mild Dementia',
    'Moderate Dementia'
]

CLASS_COLORS = [
    (0, 255, 0),      # Green
    (255, 255, 0),    # Yellow
    (255, 165, 0),    # Orange
    (0, 0, 255)       # Red
]

def preprocess_frame(frame):
    """Preprocess frame for MobileNetV2"""
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    resized = cv2.resize(gray, (224, 224))
    normalized = resized.astype(np.float32) / 255.0
    quantized = (normalized * 127).astype(np.int8)
    return quantized.reshape(1, 224, 224, 1)

def inference_worker(frame_queue, result_queue):
    """DPU inference in background thread"""
    input_data = np.zeros((1, 224, 224, 1), dtype=np.int8)
    output_data = np.zeros((1, 4), dtype=np.float32)
    
    while True:
        frame = frame_queue.get()
        if frame is None:
            break
        
        input_data = preprocess_frame(frame)
        job_id = dpu.execute_async(input_data, output_data)
        dpu.wait(job_id)
        
        pred_class = np.argmax(output_data[0])
        confidence = float(output_data[0][pred_class])
        
        result_queue.put({
            'class': CLASS_NAMES[pred_class],
            'confidence': confidence,
            'color': CLASS_COLORS[pred_class],
            'probs': output_data[0].copy()
        })

# Setup
frame_queue = queue.Queue(maxsize=2)
result_queue = queue.Queue(maxsize=2)

inference_thread = threading.Thread(
    target=inference_worker,
    args=(frame_queue, result_queue),
    daemon=True
)
inference_thread.start()

# Open webcam
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

print("âœ“ Starting inference... Press 'q' to quit\n")

latest_result = None
frame_count = 0
start_time = time.time()

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    frame_count += 1
    
    try:
        frame_queue.put_nowait(frame)
    except queue.Full:
        pass
    
    try:
        latest_result = result_queue.get_nowait()
    except queue.Empty:
        pass
    
    # Draw results
    if latest_result:
        label = f"{latest_result['class']} ({latest_result['confidence']:.1%})"
        cv2.putText(frame, label, (15, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0,
                    latest_result['color'], 2)
        
        # Draw probabilities
        y = 100
        for name, prob in zip(CLASS_NAMES, latest_result['probs']):
            cv2.putText(frame, f"{name}: {prob:.1%}", (15, y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
            y += 30
    
    # Draw FPS
    elapsed = time.time() - start_time
    fps = frame_count / elapsed if elapsed > 0 else 0
    cv2.putText(frame, f"FPS: {fps:.1f}", (15, frame.shape[0] - 20),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)
    
    cv2.imshow('Alzheimer Classification - PYNQ-ZU DPU', frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Cleanup
frame_queue.put(None)
cap.release()
cv2.destroyAllWindows()

print(f"\nCompleted {frame_count} frames in {elapsed:.1f}s ({frame_count/elapsed:.1f} FPS)")
```

### Run It

```bash
python3 webcam_inference.py
```

**Expected output:**
- Live window with webcam feed
- Real-time classification with confidence
- All 4 class probabilities
- FPS counter

---

## Performance Metrics

| Metric | CPU Only | FPGA (DPU) | Improvement |
|--------|----------|-----------|------------|
| Latency | 325 ms | 42 ms | **7.7x faster** |
| Throughput | 3 FPS | 23 FPS | **7.7x more** |
| Power | 3.7W | 2.5W | **1.5x efficient** |
| Accuracy | 95% | 93% | Comparable |

---

## Troubleshooting

### Problem: Ping doesn't work
**Solution:** 
- Check ethernet cable
- Restart board: `sudo reboot`
- Try serial console via USB

### Problem: DPU initialization fails
**Solution:**
- Verify `dpu.bit`, `dpu.hwh` are in same directory
- Check permissions: `ls -la dpu.*`
- Reinstall: `pip3 install pynq-dpu --force-reinstall`

### Problem: Webcam not detected
**Solution:**
- Check: `ls /dev/video*`
- Fix permissions: `sudo chmod 666 /dev/video0`
- Check USB: `lsusb | grep -i camera`

### Problem: Slow inference (>100ms)
**Solution:**
- Verify DPU is being used (check board logs)
- Ensure int8 model, not float32
- Check system load: `top`

---

That's it! You now have a professional edge AI system running Alzheimer's classification at 23 FPS. ðŸŽ‰
